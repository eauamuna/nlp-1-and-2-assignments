{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:17:08.212062Z","iopub.execute_input":"2025-02-18T15:17:08.212458Z","iopub.status.idle":"2025-02-18T15:17:08.219279Z","shell.execute_reply.started":"2025-02-18T15:17:08.212433Z","shell.execute_reply":"2025-02-18T15:17:08.217779Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"**1st task**","metadata":{}},{"cell_type":"code","source":"import nltk\nimport spacy\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nnlp = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:17:48.161860Z","iopub.execute_input":"2025-02-18T15:17:48.162237Z","iopub.status.idle":"2025-02-18T15:17:49.134618Z","shell.execute_reply.started":"2025-02-18T15:17:48.162207Z","shell.execute_reply":"2025-02-18T15:17:49.133410Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"text = \"\"\"Text preprocessing is an essential step in Natural Language Processing.\nIt involves tasks like tokenization, lemmatization, and stopword removal.\nThese steps help in improving the quality of textual data.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:20:28.694665Z","iopub.execute_input":"2025-02-18T15:20:28.695148Z","iopub.status.idle":"2025-02-18T15:20:28.699529Z","shell.execute_reply.started":"2025-02-18T15:20:28.695108Z","shell.execute_reply":"2025-02-18T15:20:28.698300Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"nltk_tokens = word_tokenize(text)\nprint(\"NLTK Tokenized Text:\", nltk_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:21:00.943914Z","iopub.execute_input":"2025-02-18T15:21:00.944334Z","iopub.status.idle":"2025-02-18T15:21:00.950330Z","shell.execute_reply.started":"2025-02-18T15:21:00.944301Z","shell.execute_reply":"2025-02-18T15:21:00.949111Z"}},"outputs":[{"name":"stdout","text":"NLTK Tokenized Text: ['Text', 'preprocessing', 'is', 'an', 'essential', 'step', 'in', 'Natural', 'Language', 'Processing', '.', 'It', 'involves', 'tasks', 'like', 'tokenization', ',', 'lemmatization', ',', 'and', 'stopword', 'removal', '.', 'These', 'steps', 'help', 'in', 'improving', 'the', 'quality', 'of', 'textual', 'data', '.']\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"spacy_doc = nlp(text)\nspacy_tokens = [token.text for token in spacy_doc]\nprint(\"spaCy Tokenized Text:\", spacy_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:12:35.737161Z","iopub.execute_input":"2025-02-18T15:12:35.737623Z","iopub.status.idle":"2025-02-18T15:12:35.774090Z","shell.execute_reply.started":"2025-02-18T15:12:35.737588Z","shell.execute_reply":"2025-02-18T15:12:35.772906Z"}},"outputs":[{"name":"stdout","text":"spaCy Tokenized Text: ['Text', 'preprocessing', 'is', 'an', 'essential', 'step', 'in', 'Natural', 'Language', 'Processing', '.', '\\n', 'It', 'involves', 'tasks', 'like', 'tokenization', ',', 'lemmatization', ',', 'and', 'stopword', 'removal', '.', '\\n', 'These', 'steps', 'help', 'in', 'improving', 'the', 'quality', 'of', 'textual', 'data', '.']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"nltk.data.path.append('/usr/local/nltk_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:12:39.186410Z","iopub.execute_input":"2025-02-18T15:12:39.186783Z","iopub.status.idle":"2025-02-18T15:12:39.191487Z","shell.execute_reply.started":"2025-02-18T15:12:39.186751Z","shell.execute_reply":"2025-02-18T15:12:39.190416Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from nltk.corpus import wordnet\nprint(wordnet.synsets(\"word\")) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:12:42.594446Z","iopub.execute_input":"2025-02-18T15:12:42.594824Z","iopub.status.idle":"2025-02-18T15:12:44.139341Z","shell.execute_reply.started":"2025-02-18T15:12:42.594779Z","shell.execute_reply":"2025-02-18T15:12:44.138381Z"}},"outputs":[{"name":"stdout","text":"[Synset('word.n.01'), Synset('word.n.02'), Synset('news.n.01'), Synset('word.n.04'), Synset('discussion.n.02'), Synset('parole.n.01'), Synset('word.n.07'), Synset('son.n.02'), Synset('password.n.01'), Synset('bible.n.01'), Synset('give_voice.v.01')]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\nnltk_lemmatized = [lemmatizer.lemmatize(word) for word in nltk_tokens]\nprint(\"NLTK Lemmatized Text:\", nltk_lemmatized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:12:46.536492Z","iopub.execute_input":"2025-02-18T15:12:46.536840Z","iopub.status.idle":"2025-02-18T15:12:46.544476Z","shell.execute_reply.started":"2025-02-18T15:12:46.536792Z","shell.execute_reply":"2025-02-18T15:12:46.543330Z"}},"outputs":[{"name":"stdout","text":"NLTK Lemmatized Text: ['Text', 'preprocessing', 'is', 'an', 'essential', 'step', 'in', 'Natural', 'Language', 'Processing', '.', 'It', 'involves', 'task', 'like', 'tokenization', ',', 'lemmatization', ',', 'and', 'stopword', 'removal', '.', 'These', 'step', 'help', 'in', 'improving', 'the', 'quality', 'of', 'textual', 'data', '.']\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"spacy_lemmatized = [token.lemma_ for token in spacy_doc]\nprint(\"spaCy Lemmatized Text:\", spacy_lemmatized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:15:39.233854Z","iopub.execute_input":"2025-02-18T15:15:39.234303Z","iopub.status.idle":"2025-02-18T15:15:39.240411Z","shell.execute_reply.started":"2025-02-18T15:15:39.234270Z","shell.execute_reply":"2025-02-18T15:15:39.239096Z"}},"outputs":[{"name":"stdout","text":"spaCy Lemmatized Text: ['text', 'preprocessing', 'be', 'an', 'essential', 'step', 'in', 'Natural', 'Language', 'Processing', '.', '\\n', 'it', 'involve', 'task', 'like', 'tokenization', ',', 'lemmatization', ',', 'and', 'stopword', 'removal', '.', '\\n', 'these', 'step', 'help', 'in', 'improve', 'the', 'quality', 'of', 'textual', 'datum', '.']\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nnltk_filtered = [word for word in nltk_lemmatized if word.lower() not in stop_words]\nprint(\"NLTK Processed Text (No Stopwords):\", nltk_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:15:49.170377Z","iopub.execute_input":"2025-02-18T15:15:49.170712Z","iopub.status.idle":"2025-02-18T15:15:49.177608Z","shell.execute_reply.started":"2025-02-18T15:15:49.170688Z","shell.execute_reply":"2025-02-18T15:15:49.176565Z"}},"outputs":[{"name":"stdout","text":"NLTK Processed Text (No Stopwords): ['Text', 'preprocessing', 'essential', 'step', 'Natural', 'Language', 'Processing', '.', 'involves', 'task', 'like', 'tokenization', ',', 'lemmatization', ',', 'stopword', 'removal', '.', 'step', 'help', 'improving', 'quality', 'textual', 'data', '.']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"spacy_filtered = [token.lemma_ for token in spacy_doc if not token.is_stop]\nprint(\"spaCy Processed Text (No Stopwords):\", spacy_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:16:14.017521Z","iopub.execute_input":"2025-02-18T15:16:14.017914Z","iopub.status.idle":"2025-02-18T15:16:14.023795Z","shell.execute_reply.started":"2025-02-18T15:16:14.017882Z","shell.execute_reply":"2025-02-18T15:16:14.022716Z"}},"outputs":[{"name":"stdout","text":"spaCy Processed Text (No Stopwords): ['text', 'preprocessing', 'essential', 'step', 'Natural', 'Language', 'Processing', '.', '\\n', 'involve', 'task', 'like', 'tokenization', ',', 'lemmatization', ',', 'stopword', 'removal', '.', '\\n', 'step', 'help', 'improve', 'quality', 'textual', 'datum', '.']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**2nd task**","metadata":{}},{"cell_type":"code","source":"from spacy import displacy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:23:03.395378Z","iopub.execute_input":"2025-02-18T15:23:03.395710Z","iopub.status.idle":"2025-02-18T15:23:03.399641Z","shell.execute_reply.started":"2025-02-18T15:23:03.395686Z","shell.execute_reply":"2025-02-18T15:23:03.398479Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:23:19.065355Z","iopub.execute_input":"2025-02-18T15:23:19.065741Z","iopub.status.idle":"2025-02-18T15:23:19.815562Z","shell.execute_reply.started":"2025-02-18T15:23:19.065709Z","shell.execute_reply":"2025-02-18T15:23:19.814334Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"text = \"\"\"Apple Inc. is planning to invest $1 billion in a new campus in Austin, Texas.\nThe announcement was made by CEO Tim Cook during a press conference on January 15, 2024.\nThis move is expected to create over 5,000 new jobs.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:23:41.227541Z","iopub.execute_input":"2025-02-18T15:23:41.227935Z","iopub.status.idle":"2025-02-18T15:23:41.232182Z","shell.execute_reply.started":"2025-02-18T15:23:41.227903Z","shell.execute_reply":"2025-02-18T15:23:41.230872Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"doc = nlp(text)\n\nfor ent in doc.ents:\n    print(f\"{ent.text} - {ent.label_}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:23:42.925354Z","iopub.execute_input":"2025-02-18T15:23:42.925676Z","iopub.status.idle":"2025-02-18T15:23:42.951564Z","shell.execute_reply.started":"2025-02-18T15:23:42.925651Z","shell.execute_reply":"2025-02-18T15:23:42.950596Z"}},"outputs":[{"name":"stdout","text":"Apple Inc. - ORG\n$1 billion - MONEY\nAustin - GPE\nTexas - GPE\nTim Cook - PERSON\nJanuary 15, 2024 - DATE\n5,000 - CARDINAL\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"displacy.render(doc, style=\"ent\", jupyter=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:23:57.498398Z","iopub.execute_input":"2025-02-18T15:23:57.498732Z","iopub.status.idle":"2025-02-18T15:23:57.506496Z","shell.execute_reply.started":"2025-02-18T15:23:57.498708Z","shell.execute_reply":"2025-02-18T15:23:57.505208Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Apple Inc.\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n is planning to invest \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $1 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n in a new campus in \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Austin\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n, \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Texas\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n.<br>The announcement was made by CEO \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tim Cook\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n during a press conference on \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    January 15, 2024\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n.<br>This move is expected to create over \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    5,000\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n new jobs.</div></span>"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"**3rd task**","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:27:06.675358Z","iopub.execute_input":"2025-02-18T15:27:06.675790Z","iopub.status.idle":"2025-02-18T15:27:12.088239Z","shell.execute_reply.started":"2025-02-18T15:27:06.675758Z","shell.execute_reply":"2025-02-18T15:27:12.086999Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:27:19.133424Z","iopub.execute_input":"2025-02-18T15:27:19.133790Z","iopub.status.idle":"2025-02-18T15:27:39.167675Z","shell.execute_reply.started":"2025-02-18T15:27:19.133759Z","shell.execute_reply":"2025-02-18T15:27:39.166642Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:27:45.231317Z","iopub.execute_input":"2025-02-18T15:27:45.232015Z","iopub.status.idle":"2025-02-18T15:27:49.166950Z","shell.execute_reply.started":"2025-02-18T15:27:45.231978Z","shell.execute_reply":"2025-02-18T15:27:49.165568Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6f3266093d444d927410553e2571b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7750b0e1c6402ba5b3f1f0b70387b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ea1be6703944ac9f24e6b6e5e53e00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe49ce8080f4f8f8dbdaefb67c0de7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960d46a888f9474690dafb79cdfbab14"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"text = \"Machine learning is transforming the world!\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:27:52.981300Z","iopub.execute_input":"2025-02-18T15:27:52.981656Z","iopub.status.idle":"2025-02-18T15:27:52.986186Z","shell.execute_reply.started":"2025-02-18T15:27:52.981624Z","shell.execute_reply":"2025-02-18T15:27:52.984777Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\nprint(inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:28:05.033027Z","iopub.execute_input":"2025-02-18T15:28:05.034299Z","iopub.status.idle":"2025-02-18T15:28:05.059848Z","shell.execute_reply.started":"2025-02-18T15:28:05.034255Z","shell.execute_reply":"2025-02-18T15:28:05.058358Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[  101,  3698,  4083,  2003, 17903,  1996,  2088,   999,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"with torch.no_grad():  \n    outputs = model(**inputs)\nlast_hidden_states = outputs.last_hidden_state\nprint(last_hidden_states.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:28:07.113696Z","iopub.execute_input":"2025-02-18T15:28:07.114173Z","iopub.status.idle":"2025-02-18T15:28:07.372403Z","shell.execute_reply.started":"2025-02-18T15:28:07.114135Z","shell.execute_reply":"2025-02-18T15:28:07.370839Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 9, 768])\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"sentence_embedding = last_hidden_states[:, 0, :]\nprint(sentence_embedding.shape)  # Should be [1, 768]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:28:17.428675Z","iopub.execute_input":"2025-02-18T15:28:17.429078Z","iopub.status.idle":"2025-02-18T15:28:17.434274Z","shell.execute_reply.started":"2025-02-18T15:28:17.429042Z","shell.execute_reply":"2025-02-18T15:28:17.433066Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 768])\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"**4th task**","metadata":{}},{"cell_type":"code","source":"!pip install transformers torch nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:29:16.663317Z","iopub.execute_input":"2025-02-18T15:29:16.663741Z","iopub.status.idle":"2025-02-18T15:29:21.322050Z","shell.execute_reply.started":"2025-02-18T15:29:16.663713Z","shell.execute_reply":"2025-02-18T15:29:21.320588Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"from transformers import pipeline\nsentiment_pipeline = pipeline(\"sentiment-analysis\")\nsentences = [\n    \"I love this product! It's amazing.\",\n    \"This is the worst experience I've ever had.\",\n    \"The movie was okay, but not great.\"\n]\nresults = sentiment_pipeline(sentences)\nfor text, result in zip(sentences, results):\n    print(f\"Text: {text}\\nSentiment: {result['label']} (Confidence: {result['score']:.4f})\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:29:44.780179Z","iopub.execute_input":"2025-02-18T15:29:44.780570Z","iopub.status.idle":"2025-02-18T15:29:49.768173Z","shell.execute_reply.started":"2025-02-18T15:29:44.780538Z","shell.execute_reply":"2025-02-18T15:29:49.766830Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a92cd14bf14cb0921a1098e6a2d15e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10fe53cd8fe46fab4cc32ae85d9621d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24faec90ea3d43e9a7c70a2697656e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed71a63452d432fadb7ce51acfb6d9e"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Text: I love this product! It's amazing.\nSentiment: POSITIVE (Confidence: 0.9999)\n\nText: This is the worst experience I've ever had.\nSentiment: NEGATIVE (Confidence: 0.9998)\n\nText: The movie was okay, but not great.\nSentiment: NEGATIVE (Confidence: 0.9984)\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nnltk.download(\"vader_lexicon\")\nsia = SentimentIntensityAnalyzer()\nfor text in sentences:\n    score = sia.polarity_scores(text)\n    sentiment = \"POSITIVE\" if score[\"compound\"] >= 0.05 else \"NEGATIVE\" if score[\"compound\"] <= -0.05 else \"NEUTRAL\"\n    print(f\"Text: {text}\\nSentiment: {sentiment} (Score: {score['compound']:.4f})\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T15:30:02.960186Z","iopub.execute_input":"2025-02-18T15:30:02.960581Z","iopub.status.idle":"2025-02-18T15:30:03.052698Z","shell.execute_reply.started":"2025-02-18T15:30:02.960548Z","shell.execute_reply":"2025-02-18T15:30:03.051275Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\nText: I love this product! It's amazing.\nSentiment: POSITIVE (Score: 0.8516)\n\nText: This is the worst experience I've ever had.\nSentiment: NEGATIVE (Score: -0.6249)\n\nText: The movie was okay, but not great.\nSentiment: NEGATIVE (Score: -0.6112)\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"}],"execution_count":47}]}